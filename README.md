# RAG Chatbot with Groq + LangChain + Ollama | Web-Based Contextual QA

This project implements a **Retrieval-Augmented Generation (RAG) based conversational AI system** using:
- ğŸ§  **Groqâ€™s Gemma2-9B-IT** model for fast, low-latency inference.
- ğŸ“„ **Ollama's `mxbai-embed-large`** for document embedding.
- ğŸ•¸ï¸ **Web scraping** using `WebBaseLoader` to ingest content dynamically.
- ğŸ§© **LangChain** components for orchestration.
- ğŸ§  **Chroma** for vector database and similarity search.
- ğŸ’¬ **Chat history-aware retrieval** to support multi-turn contextual Q&A.

---

## ğŸš€ Features

- ğŸ”— Web-based content ingestion and chunking.
- ğŸ” Semantic search with `OllamaEmbeddings` + Chroma.
- ğŸ’¬ Conversational memory using `MessagesPlaceholder`.
- ğŸ¤– Context-aware responses using `ChatGroq` with `gemma2-9b-it`.
- ğŸ“¦ Modular design with LangChain's RAG architecture.

---

## ğŸ§° Tech Stack

| Component | Usage |
|----------|--------|
| `LangChain` | Framework for chaining components |
| `Groq` | Fast inference using Gemma2-9B |
| `Ollama` | Local embedding model |
| `Chroma` | Vector database for storing embeddings |
| `BeautifulSoup` | Filter and parse web content |
| `dotenv` | Load environment variables |
| `bs4.SoupStrainer` | Restrict HTML parsing to specific content |

---

## ğŸ“ Project Structure

